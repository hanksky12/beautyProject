input {
 file {
   #https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html
   #default is TAIL which assumes more data will come into the file.
   #change to mode => "read" if the file is a compelte file.  by default, the file will be removed once reading is complete -- backup your files if you need them.
   mode => "tail" # 从文件末尾读取数据
   path => "/usr/share/logstash/ingest_data/*.log" # 读取的文件路径
   start_position => "beginning" # 确保从文件的开头读取数据
   sincedb_path => "/dev/null"  # 防止 sincedb 文件影响重复读取
   discover_interval => 1
 }
}


filter {
  json {
    source => "message" # 解析 JSON 格式的日志
  }

  mutate {
    # 清理字段名称，移除 JSON 字段中的方括号
    rename => { "[caller]" => "caller" }
    rename => { "[file]" => "file" }
    rename => { "[level]" => "level" }
    rename => { "[time]" => "timestamp" }
    rename => { "[request_id]" => "request_id" }
    rename => { "[go_id]" => "go_id" }
    rename => { "[user_id]" => "user_id" }
    rename => { "[user_ip]" => "user_ip" }
    rename => { "[type]" => "type" }
  }

  date {
    # 解析时间戳字段为标准时间格式
    match => [ "timestamp", "yyyy-MM-dd HH:mm:ss" ]
    timezone => "Asia/Taipei" # 明确指定原始时间是 UTC+8
    target => "@timestamp"   # 目标是标准的 @timestamp 字段
  }
}


output {
 elasticsearch {
   index => "logstash-%{+YYYY.MM.dd}"
   hosts=> "${ELASTIC_HOSTS}"
   user=> "${ELASTIC_USER}"
   password=> "${ELASTIC_PASSWORD}"
   cacert=> "certs/ca/ca.crt"
 }
}
